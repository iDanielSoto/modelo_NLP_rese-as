{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iDanielSoto/modelo_NLP_rese-as/blob/main/NLP_rese%C3%B1as.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AoAFcESJAIEz"
      },
      "source": [
        "# üìäCREACI√ìN DEL DATASET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 327,
      "metadata": {
        "id": "t7xEkrn_LGlw"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 328,
      "metadata": {
        "id": "0Vbd_bdTLMNo"
      },
      "outputs": [],
      "source": [
        "# Creaci√≥n de un dataset local sobre rese√±as buenas y malas etiquetadas con 0 = mala, 1 = buena\n",
        "data = [\n",
        "  [\"Este restaurante es realmente bueno, la comida es deliciosa y el servicio es excepcional. ¬°Volver√© definitivamente!\", 1],\n",
        "  [\"No recomendar√≠a este lugar ni siquiera a mi peor enemigo. La comida estaba fr√≠a y el personal era grosero.\", 0],\n",
        "  [\"La pel√≠cula que vi anoche fue incre√≠ble, me mantuvo al borde de mi asiento todo el tiempo. ¬°Altamente recomendada!\", 1],\n",
        "  [\"Qu√© decepci√≥n, esperaba mucho m√°s de este producto. No vale la pena el dinero que pagu√© por √©l.\", 0],\n",
        "  [\"Mi experiencia en este hotel fue maravillosa. Las habitaciones eran c√≥modas y limpias, y el personal era amable y atento. Definitivamente regresar√©.\", 1],\n",
        "  [\"Este libro es un completo desastre. La trama es confusa y los personajes son planos. No pude terminarlo.\", 0],\n",
        "  [\"¬°Qu√© maravillosa sorpresa! Esta exposici√≥n de arte me dej√≥ sin palabras. Las obras de arte eran simplemente asombrosas.\", 1],\n",
        "  [\"No volver√≠a a este lugar ni aunque me pagaran. La comida era terrible y el servicio era lento.\", 0],\n",
        "  [\"Esta nueva serie de televisi√≥n es impresionante. La historia es cautivadora y los actores hacen un trabajo excepcional.\", 1],\n",
        "  [\"Este tel√©fono es una pesadilla. Se bloquea constantemente y la bater√≠a dura menos de una hora. No lo recomiendo en absoluto.\", 0],\n",
        "]\n",
        "\n",
        "# Se guarda el dataset en un archivo csv y se clasifica por texto y etiqueta.\n",
        "with open('data_texts.csv', 'w', newline='') as csvfile:\n",
        "  csvwriter = csv.writer(csvfile)\n",
        "  csvwriter.writerow(['Texto', 'Etiqueta'])\n",
        "  csvwriter.writerows(data)\n",
        "\n",
        "# Cargar datos desde el archivo CSV\n",
        "data = pd.read_csv('data_texts.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 329,
      "metadata": {
        "id": "oPh58T04LP-Q"
      },
      "outputs": [],
      "source": [
        "# Tokenizaci√≥n del texto\n",
        "data['Texto'] = data['Texto'].apply(word_tokenize)\n",
        "\n",
        "# Convertir tokens a texto nuevamente\n",
        "data['Texto'] = data['Texto'].apply(lambda tokens: ' '.join(tokens))\n",
        "\n",
        "# Separaci√≥n de datos de entrenamiento y prueba\n",
        "train_data, test_data, train_labels, test_labels = train_test_split(data['Texto'], data['Etiqueta'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Vectorizaci√≥n\n",
        "vectorizer = CountVectorizer()\n",
        "X_train = vectorizer.fit_transform(train_data)\n",
        "X_test = vectorizer.transform(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 330,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pURbwhjkL0yn",
        "outputId": "655326f2-8ce7-44d3-9d76-b08e66e994d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matriz de entrenamiento:\n",
            "  (0, 34)\t1\n",
            "  (0, 46)\t1\n",
            "  (0, 31)\t2\n",
            "  (0, 92)\t1\n",
            "  (0, 15)\t1\n",
            "  (0, 24)\t1\n",
            "  (0, 43)\t1\n",
            "  (0, 91)\t1\n",
            "  (0, 16)\t1\n",
            "  (0, 49)\t1\n",
            "  (0, 66)\t1\n",
            "  (0, 84)\t1\n",
            "  (0, 69)\t1\n",
            "  (0, 59)\t1\n",
            "  (0, 72)\t1\n",
            "  (0, 87)\t1\n",
            "  (1, 34)\t1\n",
            "  (1, 31)\t3\n",
            "  (1, 43)\t1\n",
            "  (1, 79)\t1\n",
            "  (1, 75)\t1\n",
            "  (1, 13)\t1\n",
            "  (1, 14)\t1\n",
            "  (1, 23)\t1\n",
            "  (1, 27)\t1\n",
            "  :\t:\n",
            "  (6, 56)\t1\n",
            "  (6, 57)\t1\n",
            "  (6, 71)\t1\n",
            "  (6, 94)\t1\n",
            "  (6, 65)\t1\n",
            "  (6, 25)\t1\n",
            "  (6, 62)\t1\n",
            "  (6, 70)\t1\n",
            "  (6, 98)\t1\n",
            "  (7, 53)\t1\n",
            "  (7, 19)\t2\n",
            "  (7, 52)\t1\n",
            "  (7, 44)\t1\n",
            "  (7, 30)\t1\n",
            "  (7, 74)\t1\n",
            "  (7, 85)\t1\n",
            "  (7, 33)\t1\n",
            "  (7, 37)\t1\n",
            "  (7, 5)\t2\n",
            "  (7, 22)\t1\n",
            "  (7, 83)\t1\n",
            "  (7, 63)\t1\n",
            "  (7, 60)\t1\n",
            "  (7, 82)\t1\n",
            "  (7, 7)\t1\n",
            "Tama√±o de la matriz de entrenamiento: (8, 99)\n",
            "\n",
            "Matriz de prueba:\n",
            "  (0, 19)\t1\n",
            "  (0, 31)\t2\n",
            "  (0, 33)\t1\n",
            "  (0, 35)\t1\n",
            "  (0, 43)\t1\n",
            "  (0, 49)\t1\n",
            "  (0, 92)\t1\n",
            "  (1, 14)\t1\n",
            "  (1, 27)\t1\n",
            "  (1, 29)\t1\n",
            "  (1, 34)\t1\n",
            "  (1, 43)\t1\n",
            "  (1, 50)\t1\n",
            "  (1, 55)\t1\n",
            "  (1, 58)\t1\n",
            "  (1, 59)\t1\n",
            "  (1, 67)\t1\n",
            "Tama√±o de la matriz de prueba: (2, 99)\n"
          ]
        }
      ],
      "source": [
        "# Visualizaci√≥n de la matriz de entrenamiento y prueba\n",
        "print(\"Matriz de entrenamiento:\")\n",
        "print(X_train)\n",
        "print(\"Tama√±o de la matriz de entrenamiento:\", X_train.shape)\n",
        "\n",
        "print(\"\\nMatriz de prueba:\")\n",
        "print(X_test)\n",
        "print(\"Tama√±o de la matriz de prueba:\", X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6D1zPvKgAfxB"
      },
      "source": [
        "# ü§ñ CREACI√ìN DEL MODELO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 331,
      "metadata": {
        "id": "e_vwppRdK9uB"
      },
      "outputs": [],
      "source": [
        "# Definici√≥n y compilaci√≥n del modelo\n",
        "model = keras.Sequential([\n",
        "    layers.Input(shape=(X_train.shape[1],)),  # Capa de entrada con la forma adecuada\n",
        "    layers.Dense(64, activation='relu'),  # Capa oculta con 64 neuronas y funci√≥n de activaci√≥n ReLU\n",
        "    layers.Dense(1, activation='sigmoid')  # Capa de salida con 1 neurona y funci√≥n de activaci√≥n sigmoide (clasificaci√≥n binaria)\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',  # Optimizador Adam\n",
        "    loss='binary_crossentropy',  # P√©rdida para clasificaci√≥n binaria\n",
        "    metrics=['accuracy']  # M√©trica para medir el rendimiento\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 332,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8PtRMWAMEFY",
        "outputId": "fb9174d6-9843-4548-bb35-377119f5564c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 12s 12s/step - loss: 0.8189 - accuracy: 0.5000 - val_loss: 0.8337 - val_accuracy: 0.5000\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.7735 - accuracy: 0.5000 - val_loss: 0.8291 - val_accuracy: 0.5000\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 127ms/step - loss: 0.7305 - accuracy: 0.5000 - val_loss: 0.8247 - val_accuracy: 0.5000\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 0.6900 - accuracy: 0.5000 - val_loss: 0.8203 - val_accuracy: 0.5000\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 130ms/step - loss: 0.6513 - accuracy: 0.5000 - val_loss: 0.8160 - val_accuracy: 0.5000\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.6146 - accuracy: 0.5000 - val_loss: 0.8118 - val_accuracy: 0.5000\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 0.5802 - accuracy: 0.6250 - val_loss: 0.8073 - val_accuracy: 0.5000\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.5476 - accuracy: 0.6250 - val_loss: 0.8027 - val_accuracy: 0.5000\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 0.5167 - accuracy: 0.7500 - val_loss: 0.7981 - val_accuracy: 0.5000\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 0.4880 - accuracy: 0.8750 - val_loss: 0.7935 - val_accuracy: 0.5000\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.4606 - accuracy: 0.8750 - val_loss: 0.7888 - val_accuracy: 0.5000\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 218ms/step - loss: 0.4347 - accuracy: 0.8750 - val_loss: 0.7840 - val_accuracy: 0.5000\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.4105 - accuracy: 1.0000 - val_loss: 0.7790 - val_accuracy: 0.5000\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 337ms/step - loss: 0.3876 - accuracy: 1.0000 - val_loss: 0.7738 - val_accuracy: 0.5000\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 273ms/step - loss: 0.3662 - accuracy: 1.0000 - val_loss: 0.7687 - val_accuracy: 0.5000\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.3460 - accuracy: 1.0000 - val_loss: 0.7634 - val_accuracy: 0.5000\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 120ms/step - loss: 0.3270 - accuracy: 1.0000 - val_loss: 0.7582 - val_accuracy: 0.5000\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.3092 - accuracy: 1.0000 - val_loss: 0.7531 - val_accuracy: 0.5000\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 261ms/step - loss: 0.2925 - accuracy: 1.0000 - val_loss: 0.7479 - val_accuracy: 0.5000\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 238ms/step - loss: 0.2767 - accuracy: 1.0000 - val_loss: 0.7429 - val_accuracy: 0.5000\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 121ms/step - loss: 0.2621 - accuracy: 1.0000 - val_loss: 0.7378 - val_accuracy: 0.5000\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 0.2485 - accuracy: 1.0000 - val_loss: 0.7328 - val_accuracy: 0.5000\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 0.2357 - accuracy: 1.0000 - val_loss: 0.7277 - val_accuracy: 0.5000\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 0.2237 - accuracy: 1.0000 - val_loss: 0.7227 - val_accuracy: 0.5000\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 0.2126 - accuracy: 1.0000 - val_loss: 0.7177 - val_accuracy: 0.5000\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.2021 - accuracy: 1.0000 - val_loss: 0.7127 - val_accuracy: 0.5000\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 226ms/step - loss: 0.1922 - accuracy: 1.0000 - val_loss: 0.7076 - val_accuracy: 0.5000\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 276ms/step - loss: 0.1829 - accuracy: 1.0000 - val_loss: 0.7027 - val_accuracy: 0.5000\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.1741 - accuracy: 1.0000 - val_loss: 0.6978 - val_accuracy: 0.5000\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 259ms/step - loss: 0.1658 - accuracy: 1.0000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 228ms/step - loss: 0.1579 - accuracy: 1.0000 - val_loss: 0.6885 - val_accuracy: 0.5000\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 261ms/step - loss: 0.1505 - accuracy: 1.0000 - val_loss: 0.6841 - val_accuracy: 0.5000\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 280ms/step - loss: 0.1435 - accuracy: 1.0000 - val_loss: 0.6799 - val_accuracy: 0.5000\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 343ms/step - loss: 0.1369 - accuracy: 1.0000 - val_loss: 0.6759 - val_accuracy: 0.5000\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 331ms/step - loss: 0.1306 - accuracy: 1.0000 - val_loss: 0.6723 - val_accuracy: 0.5000\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.1247 - accuracy: 1.0000 - val_loss: 0.6689 - val_accuracy: 0.5000\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 202ms/step - loss: 0.1191 - accuracy: 1.0000 - val_loss: 0.6658 - val_accuracy: 0.5000\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 234ms/step - loss: 0.1138 - accuracy: 1.0000 - val_loss: 0.6627 - val_accuracy: 0.5000\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 240ms/step - loss: 0.1088 - accuracy: 1.0000 - val_loss: 0.6597 - val_accuracy: 0.5000\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 243ms/step - loss: 0.1041 - accuracy: 1.0000 - val_loss: 0.6567 - val_accuracy: 0.5000\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 334ms/step - loss: 0.0997 - accuracy: 1.0000 - val_loss: 0.6536 - val_accuracy: 0.5000\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 0.0955 - accuracy: 1.0000 - val_loss: 0.6505 - val_accuracy: 0.5000\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 221ms/step - loss: 0.0915 - accuracy: 1.0000 - val_loss: 0.6476 - val_accuracy: 0.5000\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 318ms/step - loss: 0.0878 - accuracy: 1.0000 - val_loss: 0.6449 - val_accuracy: 0.5000\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 245ms/step - loss: 0.0843 - accuracy: 1.0000 - val_loss: 0.6423 - val_accuracy: 0.5000\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.0809 - accuracy: 1.0000 - val_loss: 0.6400 - val_accuracy: 0.5000\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 203ms/step - loss: 0.0776 - accuracy: 1.0000 - val_loss: 0.6377 - val_accuracy: 0.5000\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.0745 - accuracy: 1.0000 - val_loss: 0.6354 - val_accuracy: 0.5000\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.0716 - accuracy: 1.0000 - val_loss: 0.6331 - val_accuracy: 0.5000\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.0689 - accuracy: 1.0000 - val_loss: 0.6308 - val_accuracy: 0.5000\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 0.0663 - accuracy: 1.0000 - val_loss: 0.6286 - val_accuracy: 0.5000\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.0638 - accuracy: 1.0000 - val_loss: 0.6265 - val_accuracy: 0.5000\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 204ms/step - loss: 0.0615 - accuracy: 1.0000 - val_loss: 0.6244 - val_accuracy: 0.5000\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 204ms/step - loss: 0.0593 - accuracy: 1.0000 - val_loss: 0.6221 - val_accuracy: 0.5000\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 0.0571 - accuracy: 1.0000 - val_loss: 0.6200 - val_accuracy: 0.5000\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 0.0551 - accuracy: 1.0000 - val_loss: 0.6178 - val_accuracy: 0.5000\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.0532 - accuracy: 1.0000 - val_loss: 0.6157 - val_accuracy: 0.5000\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 201ms/step - loss: 0.0514 - accuracy: 1.0000 - val_loss: 0.6137 - val_accuracy: 0.5000\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 205ms/step - loss: 0.0497 - accuracy: 1.0000 - val_loss: 0.6116 - val_accuracy: 0.5000\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 233ms/step - loss: 0.0480 - accuracy: 1.0000 - val_loss: 0.6096 - val_accuracy: 0.5000\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 0.0465 - accuracy: 1.0000 - val_loss: 0.6077 - val_accuracy: 0.5000\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.0450 - accuracy: 1.0000 - val_loss: 0.6058 - val_accuracy: 0.5000\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 0.0436 - accuracy: 1.0000 - val_loss: 0.6039 - val_accuracy: 0.5000\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 0.0422 - accuracy: 1.0000 - val_loss: 0.6020 - val_accuracy: 0.5000\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 0.0409 - accuracy: 1.0000 - val_loss: 0.6000 - val_accuracy: 0.5000\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 0.0397 - accuracy: 1.0000 - val_loss: 0.5980 - val_accuracy: 0.5000\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 0.0385 - accuracy: 1.0000 - val_loss: 0.5960 - val_accuracy: 0.5000\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 227ms/step - loss: 0.0374 - accuracy: 1.0000 - val_loss: 0.5940 - val_accuracy: 0.5000\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 197ms/step - loss: 0.0363 - accuracy: 1.0000 - val_loss: 0.5921 - val_accuracy: 0.5000\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.0353 - accuracy: 1.0000 - val_loss: 0.5903 - val_accuracy: 0.5000\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.0343 - accuracy: 1.0000 - val_loss: 0.5884 - val_accuracy: 0.5000\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.0333 - accuracy: 1.0000 - val_loss: 0.5866 - val_accuracy: 0.5000\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.0324 - accuracy: 1.0000 - val_loss: 0.5850 - val_accuracy: 0.5000\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.0316 - accuracy: 1.0000 - val_loss: 0.5834 - val_accuracy: 0.5000\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 0.0307 - accuracy: 1.0000 - val_loss: 0.5818 - val_accuracy: 0.5000\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.0299 - accuracy: 1.0000 - val_loss: 0.5802 - val_accuracy: 0.5000\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 230ms/step - loss: 0.0291 - accuracy: 1.0000 - val_loss: 0.5786 - val_accuracy: 0.5000\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.0284 - accuracy: 1.0000 - val_loss: 0.5770 - val_accuracy: 0.5000\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.0276 - accuracy: 1.0000 - val_loss: 0.5756 - val_accuracy: 0.5000\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 0.0269 - accuracy: 1.0000 - val_loss: 0.5743 - val_accuracy: 0.5000\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 237ms/step - loss: 0.0262 - accuracy: 1.0000 - val_loss: 0.5731 - val_accuracy: 0.5000\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.0255 - accuracy: 1.0000 - val_loss: 0.5718 - val_accuracy: 0.5000\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.0249 - accuracy: 1.0000 - val_loss: 0.5706 - val_accuracy: 0.5000\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 0.0242 - accuracy: 1.0000 - val_loss: 0.5694 - val_accuracy: 0.5000\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 128ms/step - loss: 0.0236 - accuracy: 1.0000 - val_loss: 0.5682 - val_accuracy: 0.5000\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 0.0230 - accuracy: 1.0000 - val_loss: 0.5671 - val_accuracy: 0.5000\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 0.0225 - accuracy: 1.0000 - val_loss: 0.5660 - val_accuracy: 0.5000\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.0219 - accuracy: 1.0000 - val_loss: 0.5649 - val_accuracy: 0.5000\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 0.0214 - accuracy: 1.0000 - val_loss: 0.5639 - val_accuracy: 0.5000\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 205ms/step - loss: 0.0209 - accuracy: 1.0000 - val_loss: 0.5628 - val_accuracy: 0.5000\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.0204 - accuracy: 1.0000 - val_loss: 0.5618 - val_accuracy: 0.5000\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.0199 - accuracy: 1.0000 - val_loss: 0.5608 - val_accuracy: 0.5000\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.0194 - accuracy: 1.0000 - val_loss: 0.5597 - val_accuracy: 0.5000\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 0.5587 - val_accuracy: 0.5000\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 0.0185 - accuracy: 1.0000 - val_loss: 0.5577 - val_accuracy: 0.5000\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 0.5566 - val_accuracy: 0.5000\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 0.5556 - val_accuracy: 0.5000\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 0.5546 - val_accuracy: 0.5000\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: 0.5536 - val_accuracy: 0.5000\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 0.5525 - val_accuracy: 0.5000\n"
          ]
        }
      ],
      "source": [
        "# Entrenamiento del modelo\n",
        "history = model.fit(X_train.toarray(), train_labels,  # Datos de entrenamiento y etiquetas\n",
        " validation_data=(X_test.toarray(), test_labels),  # Datos de prueba y etiquetas\n",
        "  epochs=100,  # N√∫mero de √©pocas\n",
        "  batch_size=8)  # Tama√±o del lote\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 333,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2FcGLgmXDzy",
        "outputId": "b9086e60-87b9-4a8b-922c-9eeb64ded191"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 134ms/step - loss: 0.5525 - accuracy: 0.5000\n",
            "Precisi√≥n en datos de prueba: 0.5000\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_accuracy = model.evaluate(X_test.toarray(), test_labels)\n",
        "print(f'Precisi√≥n en datos de prueba: {test_accuracy:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ooO19VeuZzve"
      },
      "source": [
        "# üíª PROGRAMA FINAL: PREDICCI√ìN DE RESE√ëAS POSITIVAS O NEGATIVAS."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 334,
      "metadata": {
        "cellView": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YswlRdUKXHK_",
        "outputId": "04e99946-5927-4b15-b7c6-814074a72b27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hay un 51.70% de que sea positiva. (0.5170)\n",
            "La rese√±a es POSITIVA ‚úÖ\n"
          ]
        }
      ],
      "source": [
        "# @title ‚≠ê Escribe una rese√±a sobre alg√∫n lugar. { vertical-output: true, form-width: \"75%\" }\n",
        "new_text = [\"Muy buen sitio, me encanto la comida.\"]  # Convierte la cadena de texto en una lista de un solo elemento\n",
        "new_text_vectorized = vectorizer.transform(new_text)  # Vectorizaci√≥n del nuevo texto\n",
        "prediction = model.predict(new_text_vectorized, verbose=False)\n",
        "predicted_probability = prediction[0, 0] * 100  # Convierte la probabilidad en porcentaje\n",
        "print(f'Hay un {predicted_probability:.2f}% de que sea positiva. ({prediction[0, 0]:.4f})')\n",
        "threshold = 0.5  # Umbral para clasificar como positiva o negativa\n",
        "if prediction[0, 0] > threshold:\n",
        "  print(\"La rese√±a es POSITIVA ‚úÖ\")\n",
        "else:\n",
        "  print(\"La rese√±a es NEGATIVA ‚ùå\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOXdQnZu4kLia47u817I5YY",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}